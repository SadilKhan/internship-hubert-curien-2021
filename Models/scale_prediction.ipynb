{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "scale_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "metadata": {
      "interpreter": {
        "hash": "7a42647e4c83c11f35b3df9f93177de0f6edb84fc1cf48b1d5ae91b569103241"
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8OyDt9vhmuw"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchsummary import summary\n",
        "import torch.optim as optim\n",
        "import torchcontrib.optim as optim_contrib\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ID5AwyEWkfW2",
        "outputId": "89bb96e2-73ec-4486-f327-504bf724df70"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMDsQrOThrEi",
        "outputId": "4592246f-bb2b-4c19-f531-4efe52f8ed5d"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jre4rm2hmuz",
        "outputId": "7a4b273b-ea6f-403d-a3a0-35751ac4506e"
      },
      "source": [
        "PATH=\"/content/gdrive/MyDrive\"\n",
        "os.listdir(PATH)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Colab Notebooks', 'train_images', 'csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxj6x5lehmu0"
      },
      "source": [
        "# Declaring Global Varibles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUpTuKXNhmu0"
      },
      "source": [
        "CSV_PATH=PATH+\"/csv\"\n",
        "IMAGE_PATH=PATH+\"/train_images\"\n",
        "BS=8\n",
        "LR=0.1\n",
        "WEIGHT_DECAY=5E-4\n",
        "EPOCH=10"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYO3KYumhmu1"
      },
      "source": [
        "# Importing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "n5SuB1FLhmu1",
        "outputId": "40c3a3d2-61f2-4249-b704-2a2c656dd4e6"
      },
      "source": [
        "data=pd.read_csv(CSV_PATH+\"/train.csv\")\n",
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>label</th>\n",
              "      <th>template_name</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0181 copie.jpg</td>\n",
              "      <td>0181 copie_0</td>\n",
              "      <td>0181 copie_0_0.jpg</td>\n",
              "      <td>216</td>\n",
              "      <td>696</td>\n",
              "      <td>545</td>\n",
              "      <td>1040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0181 copie.jpg</td>\n",
              "      <td>0181 copie_0_flipped</td>\n",
              "      <td>0181 copie_0_flipped_0.jpg</td>\n",
              "      <td>852</td>\n",
              "      <td>687</td>\n",
              "      <td>1210</td>\n",
              "      <td>1038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0181 copie.jpg</td>\n",
              "      <td>0181 copie_1</td>\n",
              "      <td>0181 copie_1_0.jpg</td>\n",
              "      <td>557</td>\n",
              "      <td>701</td>\n",
              "      <td>861</td>\n",
              "      <td>1080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0181 copie.jpg</td>\n",
              "      <td>0181 copie_2</td>\n",
              "      <td>0181 copie_2_0.jpg</td>\n",
              "      <td>194</td>\n",
              "      <td>1201</td>\n",
              "      <td>419</td>\n",
              "      <td>1380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0181 copie.jpg</td>\n",
              "      <td>0181 copie_2</td>\n",
              "      <td>0181 copie_2_1.jpg</td>\n",
              "      <td>1019</td>\n",
              "      <td>1201</td>\n",
              "      <td>1275</td>\n",
              "      <td>1379</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       image_name                 label  ...  xmax  ymax\n",
              "0  0181 copie.jpg          0181 copie_0  ...   545  1040\n",
              "1  0181 copie.jpg  0181 copie_0_flipped  ...  1210  1038\n",
              "2  0181 copie.jpg          0181 copie_1  ...   861  1080\n",
              "3  0181 copie.jpg          0181 copie_2  ...   419  1380\n",
              "4  0181 copie.jpg          0181 copie_2  ...  1275  1379\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-q_yEfRhmu2",
        "outputId": "5af3cc80-3d20-41be-a010-44aca0d1db39"
      },
      "source": [
        "image_names=data['image_name'].unique()\n",
        "print(f\"We have {len(image_names)} images\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have 18 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbRGIEHmhmu2"
      },
      "source": [
        "# Store the arrays of the image\n",
        "image_names=list(data['image_name'].unique())\n",
        "imageArray=pd.DataFrame({\"image_name\":[],\"image_array\":[]})\n",
        "for im in image_names:\n",
        "  img=Image.open(IMAGE_PATH+\"/\"+im)\n",
        "  imageArray=pd.concat([imageArray,pd.DataFrame({\"image_name\":[im],\"image_array\":[np.array(img)]})])\n",
        "  del img"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Mcp3xykchmu2",
        "outputId": "27cfd629-1c61-4af6-e155-a9c0aa187473"
      },
      "source": [
        "imageArray.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>image_array</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0181 copie.jpg</td>\n",
              "      <td>[[[145, 138, 132], [140, 133, 127], [140, 133,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0183 copie.jpg</td>\n",
              "      <td>[[[153, 146, 140], [165, 158, 152], [133, 126,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0185 copie.jpg</td>\n",
              "      <td>[[[163, 156, 148], [156, 149, 141], [151, 144,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0187 copie.jpg</td>\n",
              "      <td>[[[151, 144, 138], [151, 144, 138], [148, 141,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0189 copie.jpg</td>\n",
              "      <td>[[[143, 136, 130], [146, 139, 133], [133, 126,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       image_name                                        image_array\n",
              "0  0181 copie.jpg  [[[145, 138, 132], [140, 133, 127], [140, 133,...\n",
              "0  0183 copie.jpg  [[[153, 146, 140], [165, 158, 152], [133, 126,...\n",
              "0  0185 copie.jpg  [[[163, 156, 148], [156, 149, 141], [151, 144,...\n",
              "0  0187 copie.jpg  [[[151, 144, 138], [151, 144, 138], [148, 141,...\n",
              "0  0189 copie.jpg  [[[143, 136, 130], [146, 139, 133], [133, 126,..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm7RxbEohmu3"
      },
      "source": [
        "# Pretext Task\n",
        "\n",
        "    > Predict Scale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63UjbMFshmu3"
      },
      "source": [
        "# We won't save the arrays of the rescaled image, we will save the scaling factor and coordinates for crop\n",
        "scaleData=pd.DataFrame({\"image_name\":[],\"x_min\":[],\"y_min\":[],\"x_max\":[],\"y_max\":[],\"scaling_factor\":[]})\n",
        "scaleData[\"x_min\"]=scaleData[\"image_name\"].apply(lambda x:0)\n",
        "scaleData[\"y_min\"]=scaleData[\"image_name\"].apply(lambda x:0)\n",
        "scaleData[\"x_max\"]=scaleData[\"image_name\"].apply(lambda x:\n",
        "                                                 imageArray[imageArray[\"image_name\"]==x][\"image_array\"][0].shape[1])\n",
        "scaleData[\"y_max\"]=scaleData[\"image_name\"].apply(lambda x:\n",
        "                                                 imageArray[imageArray[\"image_name\"]==x][\"image_array\"][0].shape[0])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0JMLxvEhmu3"
      },
      "source": [
        "# We will randomly crop an image and scale it to 300 * 300 and store the scaling factor as a target variable\n",
        "scaling_factors=np.arange(1,3.1,0.1)\n",
        "def rescale_crop(num,image_name):\n",
        "    \"\"\" Randomly crop an image and scale it to 300 * 300 \"\"\"\n",
        "    global scaleData\n",
        "    global data\n",
        "    global scaling_factors\n",
        "\n",
        "    h,w=imageArray[imageArray['image_name']==image_name][\"image_array\"].values[0].shape[:2]\n",
        "\n",
        "    # Choose randomly a scaling factor\n",
        "    sc=np.random.choice(scaling_factors)\n",
        "\n",
        "    # Calculate the height and width\n",
        "    new_w=int(300*sc)\n",
        "    new_h=int(300*sc)\n",
        "\n",
        "    # Choose randomly the coordinates\n",
        "    new_x=int(np.random.randint(0,w-2*new_w))\n",
        "    new_y=int(np.random.randint(0,h-new_h))\n",
        "\n",
        "    # image name\n",
        "    name=image_name.split(\".\")[0]+\"_scale_\"+str(num)+\".jpg\"\n",
        "\n",
        "    scaleData=pd.concat([scaleData,pd.DataFrame({\"image_name\":[name],\"x_min\":[new_x],\n",
        "    \"y_min\":[new_y],\"x_max\":[new_x+new_w],\"y_max\":[new_y+new_h],\"scaling_factor\":[sc]})])"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RG39_yMhmu4",
        "outputId": "2db3d5af-ec91-4d24-d27d-db88d6dd985a"
      },
      "source": [
        "%%time\n",
        "for im in image_names:\n",
        "    for i in range(200):\n",
        "        rescale_crop(i,im)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10.6 s, sys: 279 ms, total: 10.9 s\n",
            "Wall time: 10.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbU44dcnupzc"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IznPK9qTux7o"
      },
      "source": [
        "scaleData=pd.read_csv(\"/content/gdrive/MyDrive/csv/scaleData.csv\")"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "KxAJHUFqhmu4",
        "outputId": "68462446-21f6-49c9-d07d-18478f8c0768"
      },
      "source": [
        "scaleData.head()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>x_min</th>\n",
              "      <th>y_min</th>\n",
              "      <th>x_max</th>\n",
              "      <th>y_max</th>\n",
              "      <th>scaling_factor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0181 copie_scale_0.jpg</td>\n",
              "      <td>562.0</td>\n",
              "      <td>2536.0</td>\n",
              "      <td>1282.0</td>\n",
              "      <td>3256.0</td>\n",
              "      <td>2.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0181 copie_scale_1.jpg</td>\n",
              "      <td>939.0</td>\n",
              "      <td>3042.0</td>\n",
              "      <td>1269.0</td>\n",
              "      <td>3372.0</td>\n",
              "      <td>1.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0181 copie_scale_2.jpg</td>\n",
              "      <td>88.0</td>\n",
              "      <td>1868.0</td>\n",
              "      <td>478.0</td>\n",
              "      <td>2258.0</td>\n",
              "      <td>1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0181 copie_scale_3.jpg</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>486.0</td>\n",
              "      <td>1533.0</td>\n",
              "      <td>816.0</td>\n",
              "      <td>1.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0181 copie_scale_4.jpg</td>\n",
              "      <td>901.0</td>\n",
              "      <td>2204.0</td>\n",
              "      <td>1471.0</td>\n",
              "      <td>2774.0</td>\n",
              "      <td>1.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               image_name   x_min   y_min   x_max   y_max  scaling_factor\n",
              "0  0181 copie_scale_0.jpg   562.0  2536.0  1282.0  3256.0             2.4\n",
              "1  0181 copie_scale_1.jpg   939.0  3042.0  1269.0  3372.0             1.1\n",
              "2  0181 copie_scale_2.jpg    88.0  1868.0   478.0  2258.0             1.3\n",
              "3  0181 copie_scale_3.jpg  1203.0   486.0  1533.0   816.0             1.1\n",
              "4  0181 copie_scale_4.jpg   901.0  2204.0  1471.0  2774.0             1.9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78wUzLS-hmu4"
      },
      "source": [
        "le=LabelEncoder()\n",
        "scaleData['scaling_factor']=le.fit_transform(scaleData['scaling_factor'])"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmpSq8oshmu5"
      },
      "source": [
        "\n",
        "#scaleData.to_csv(CSV_PATH+\"/\"+\"scaleData.csv\",index=None)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGPA7coOhmu7"
      },
      "source": [
        "class ScaleDataset(Dataset):\n",
        "    def __init__(self, dataset, image_dataset, is_test=False, transform=None):\n",
        "        #self.annotation_folder_path = csv_path\n",
        "        self.dataset=dataset\n",
        "        self.image_dataset=image_dataset\n",
        "        self.all_images=self.dataset['image_name'].unique()\n",
        "        self.transform = transform\n",
        "        self.is_test = is_test\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        img_name=self.all_images[idx]\n",
        "        original_img_name=img_name.split(\"_\")[0]+\".jpg\"\n",
        "        coord=self.dataset[self.dataset['image_name']==img_name][[\"x_min\",\"y_min\",\"x_max\",\"y_max\"]].values[0]\n",
        "        img=Image.fromarray(self.image_dataset[self.image_dataset['image_name']==original_img_name]['image_array'].values[0][\n",
        "            int(coord[1]):int(coord[3]),int(coord[0]):int(coord[2])])\n",
        "        #img=img.convert(\"RGB\")\n",
        "\n",
        "        if not self.is_test:\n",
        "            annotations=self.dataset[self.dataset['image_name']==img_name]\n",
        "\n",
        "            #self.box = self.get_xy(annotations)\n",
        "\n",
        "            #self.new_box = torch.FloatTensor(self.box_resize(self.box, img))\n",
        "            if self.transform is not None:\n",
        "                img = self.transform(img)\n",
        "            \n",
        "\n",
        "            self.labels=torch.FloatTensor(annotations['scaling_factor'].values)\n",
        "\n",
        "            return img, self.labels\n",
        "        else:\n",
        "            return img\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.all_images)\n",
        "        \n",
        "    \n",
        "    def collate_fn(self, batch):\n",
        "        \"\"\"\n",
        "        :param batch: an iterable of N sets from __getitem__()\n",
        "        :return: a tensor of images, lists of varying-size tensors of bounding boxes, labels, and difficulties\n",
        "        \"\"\"\n",
        "\n",
        "        images = list()\n",
        "        labels = list()\n",
        "#         difficulties = list()\n",
        "\n",
        "        for b in batch:\n",
        "            images.append(b[0])\n",
        "            labels.append(b[1])\n",
        "#             difficulties.append(b[3])\n",
        "\n",
        "        images = torch.stack(images, dim=0)\n",
        "\n",
        "        return images, labels\n",
        "\n"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6aLY8K0hmu7"
      },
      "source": [
        "tsfm = transforms.Compose([\n",
        "    transforms.Resize([300,300]),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0Tkpn2qhmu7"
      },
      "source": [
        "x_train,x_test=train_test_split(scaleData,test_size=0.15,random_state=1)"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EML7sjdPhmu8"
      },
      "source": [
        "train_ds = ScaleDataset(x_train,imageArray,transform=tsfm)\n",
        "train_dl = DataLoader(train_ds, batch_size=BS, shuffle=True, collate_fn=train_ds.collate_fn)\n",
        "\n",
        "valid_ds = ScaleDataset(x_test,imageArray, transform=tsfm)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=BS, shuffle=True, collate_fn=valid_ds.collate_fn)"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXct64db9T9y"
      },
      "source": [
        "x=next(iter(train_dl))"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6eYeVOQ9ftZ",
        "outputId": "61a7aa9e-82a9-4643-90fe-1703e75b30b8"
      },
      "source": [
        "print(f\"Size of the Patch {x[0][0].shape}, scaling factor {le.inverse_transform([int(x[1][0].item())])[0]}\")"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of the Patch torch.Size([3, 690, 690]), scaling factor 2.3000000000000007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V__XS1NDhmu8"
      },
      "source": [
        "def decimate(tensor, m):\n",
        "    \"\"\"\n",
        "    Decimate a tensor by a factor 'm', i.e. downsample by keeping every 'm'th value.\n",
        "    This is used when we convert FC layers to equivalent Convolutional layers, BUT of a smaller size.\n",
        "    :param tensor: tensor to be decimated\n",
        "    :param m: list of decimation factors for each dimension of the tensor; None if not to be decimated along a dimension\n",
        "    :return: decimated tensor\n",
        "    \"\"\"\n",
        "    assert tensor.dim() == len(m)\n",
        "    for d in range(tensor.dim()):\n",
        "        if m[d] is not None:\n",
        "            tensor = tensor.index_select(dim=d,\n",
        "                                         index=torch.arange(start=0, end=tensor.size(d), step=m[d]).long())\n",
        "\n",
        "    return tensor\n",
        "class VGGBase(nn.Module):\n",
        "    \"\"\"\n",
        "    VGG base convolutions to produce lower-level feature maps.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(VGGBase, self).__init__()\n",
        "\n",
        "        # Standard convolutional layers in VGG16\n",
        "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)  # stride = 1, by default\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)  # ceiling (not floor) here for even dims\n",
        "\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.conv6=nn.Conv2d(512,256,kernel_size=1)\n",
        "        self.conv7=nn.Conv2d(256,64,kernel_size=1)\n",
        "        self.pool5=nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Linear Layers\n",
        "        self.output=nn.Linear(in_features=64*9*9,out_features=21)\n",
        "\n",
        "\n",
        "    def forward(self, image):\n",
        "        \"\"\"\n",
        "        Forward propagation.\n",
        "        :param image: images, a tensor of dimensions (N, 3, 300, 300)\n",
        "        :return: lower-level feature maps conv4_3 and conv7\n",
        "        \"\"\"\n",
        "        out = F.relu(self.conv1_1(image))  # (N, 64, 300, 300)\n",
        "        out = F.relu(self.conv1_2(out))  # (N, 64, 300, 300)\n",
        "        out = self.pool1(out)  # (N, 64, 150, 150)\n",
        "\n",
        "        out = F.relu(self.conv2_1(out))  # (N, 128, 150, 150)\n",
        "        out = F.relu(self.conv2_2(out))  # (N, 128, 150, 150)\n",
        "        out = self.pool2(out)  # (N, 128, 75, 75)\n",
        "\n",
        "        out = F.relu(self.conv3_1(out))  # (N, 256, 75, 75)\n",
        "        out = F.relu(self.conv3_2(out))  # (N, 256, 75, 75)\n",
        "        out = F.relu(self.conv3_3(out))  # (N, 256, 75, 75)\n",
        "        out = self.pool3(out)  # (N, 256, 38, 38), it would have been 37 if not for ceil_mode = True\n",
        "\n",
        "        out = F.relu(self.conv4_1(out))  # (N, 512, 38, 38)\n",
        "        out = F.relu(self.conv4_2(out))  # (N, 512, 38, 38)\n",
        "        out = F.relu(self.conv4_3(out))  # (N, 512, 38, 38)\n",
        "        conv4_3_feats = out  # (N, 512, 38, 38)\n",
        "        out = self.pool4(out)  # (N, 512, 19, 19)\n",
        "\n",
        "        out = F.relu(self.conv5_1(out))  # (N, 512, 19, 19)\n",
        "        out=F.relu(self.conv6(out))\n",
        "        out=F.relu(self.conv7(out))\n",
        "        out=F.relu(self.pool5(out))\n",
        "\n",
        "        # Linear Layers\n",
        "        flattened_array=out.reshape(-1,64*9*9)\n",
        "        output=F.softmax(self.output(flattened_array))\n",
        "\n",
        "        # Return output\n",
        "        return output"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIIpGNPXhmu9"
      },
      "source": [
        "vgg=VGGBase().to(\"cuda:0\")"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVX-giE2hmu9",
        "outputId": "c34093d8-13fe-4631-c57c-79eb414a2e5e"
      },
      "source": [
        "summary(vgg,(3,300,300))"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 300, 300]           1,792\n",
            "            Conv2d-2         [-1, 64, 300, 300]          36,928\n",
            "         MaxPool2d-3         [-1, 64, 150, 150]               0\n",
            "            Conv2d-4        [-1, 128, 150, 150]          73,856\n",
            "            Conv2d-5        [-1, 128, 150, 150]         147,584\n",
            "         MaxPool2d-6          [-1, 128, 75, 75]               0\n",
            "            Conv2d-7          [-1, 256, 75, 75]         295,168\n",
            "            Conv2d-8          [-1, 256, 75, 75]         590,080\n",
            "            Conv2d-9          [-1, 256, 75, 75]         590,080\n",
            "        MaxPool2d-10          [-1, 256, 38, 38]               0\n",
            "           Conv2d-11          [-1, 512, 38, 38]       1,180,160\n",
            "           Conv2d-12          [-1, 512, 38, 38]       2,359,808\n",
            "           Conv2d-13          [-1, 512, 38, 38]       2,359,808\n",
            "        MaxPool2d-14          [-1, 512, 19, 19]               0\n",
            "           Conv2d-15          [-1, 512, 19, 19]       2,359,808\n",
            "           Conv2d-16          [-1, 256, 19, 19]         131,328\n",
            "           Conv2d-17           [-1, 64, 19, 19]          16,448\n",
            "        MaxPool2d-18             [-1, 64, 9, 9]               0\n",
            "           Linear-19                   [-1, 21]         108,885\n",
            "================================================================\n",
            "Total params: 10,251,733\n",
            "Trainable params: 10,251,733\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.03\n",
            "Forward/backward pass size (MB): 204.76\n",
            "Params size (MB): 39.11\n",
            "Estimated Total Size (MB): 244.90\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:84: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v-7Occz7oKp"
      },
      "source": [
        "class COCOBBackprop(optim.Optimizer):\n",
        "\n",
        "  \"\"\" From https://github.com/anandsaha/nips.cocob.pytorch/blob/master/cocob.py \"\"\"\n",
        "    \n",
        "  def __init__(self, params, alpha=100, epsilon=1e-8):\n",
        "      \n",
        "      self._alpha = alpha\n",
        "      self.epsilon = epsilon\n",
        "      defaults = dict(alpha=alpha, epsilon=epsilon)\n",
        "      super(COCOBBackprop, self).__init__(params, defaults)\n",
        "      \n",
        "  def step(self, closure=None):\n",
        "      \n",
        "      loss = None\n",
        "      \n",
        "      if closure is not None:\n",
        "          loss = closure()\n",
        "          \n",
        "      for group in self.param_groups:\n",
        "          for p in group['params']:\n",
        "              if p.grad is None:\n",
        "                  continue\n",
        "      \n",
        "              grad = p.grad.data\n",
        "              state = self.state[p]\n",
        "              \n",
        "              if len(state) == 0:\n",
        "                  state['gradients_sum'] = torch.zeros_like(p.data).cuda().float()\n",
        "                  state['grad_norm_sum'] = torch.zeros_like(p.data).cuda().float()\n",
        "                  state['L'] = self.epsilon * torch.ones_like(p.data).cuda().float()\n",
        "                  state['tilde_w'] = torch.zeros_like(p.data).cuda().float()\n",
        "                  state['reward'] = torch.zeros_like(p.data).cuda().float()\n",
        "                  \n",
        "              gradients_sum = state['gradients_sum']\n",
        "              grad_norm_sum = state['grad_norm_sum']\n",
        "              tilde_w = state['tilde_w']\n",
        "              L = state['L']\n",
        "              reward = state['reward']\n",
        "              \n",
        "              zero = torch.cuda.FloatTensor([0.])\n",
        "              \n",
        "              L_update = torch.max(L, torch.abs(grad))\n",
        "              gradients_sum_update = gradients_sum + grad\n",
        "              grad_norm_sum_update = grad_norm_sum + torch.abs(grad)\n",
        "              reward_update = torch.max(reward - grad * tilde_w, zero)\n",
        "              new_w = -gradients_sum_update/(L_update * (torch.max(grad_norm_sum_update + L_update, self._alpha * L_update)))*(reward_update + L_update)\n",
        "              p.data = p.data - tilde_w + new_w\n",
        "              tilde_w_update = new_w\n",
        "              \n",
        "              state['gradients_sum'] = gradients_sum_update\n",
        "              state['grad_norm_sum'] = grad_norm_sum_update\n",
        "              state['L'] = L_update\n",
        "              state['tilde_w'] = tilde_w_update\n",
        "              state['reward'] = reward_update\n",
        "\n",
        "      return loss"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKYfx6MUhmu-"
      },
      "source": [
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=COCOBBackprop(vgg.parameters())"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TmE0Zj-hmu-",
        "outputId": "b1ca61aa-8786-4e6c-e0a3-d40ccd4db74e"
      },
      "source": [
        "\n",
        "for epoch in range(EPOCH):\n",
        "    vgg.train()\n",
        "    train_loss=[]\n",
        "    train_accuracy=[]\n",
        "    test_accuracy=[]\n",
        "    test_loss=[]\n",
        "    for step,(img,labels) in enumerate(train_dl):\n",
        "        labels=torch.tensor(labels)\n",
        "        labels=labels.long()\n",
        "        labels=labels.to(\"cuda:0\")\n",
        "        img=img.to(\"cuda:0\")\n",
        "        pred=vgg(img)\n",
        "        loss=criterion(pred,labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss.append(loss.item())\n",
        "        accuracy=accuracy_score(labels.tolist(),torch.argmax(pred,dim=1).tolist())\n",
        "        train_accuracy.append(accuracy)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for step,(img,labels) in enumerate(valid_dl):\n",
        "        labels=torch.tensor(labels)\n",
        "        labels=labels.long()\n",
        "        labels=labels.to(\"cuda:0\")\n",
        "        img=img.to(\"cuda:0\")\n",
        "        pred=vgg(img)\n",
        "        val_loss=criterion(pred,labels)\n",
        "\n",
        "        test_loss.append(val_loss.item())\n",
        "        accuracy=accuracy_score(labels.tolist(),torch.argmax(pred,dim=1).tolist())\n",
        "        test_accuracy.append(accuracy)\n",
        "\n",
        "    \n",
        "    print(f\"Epoch {epoch+1}, train loss: {np.mean(train_loss)}, test loss: {np.mean(test_loss)}\\n\")\n",
        "    print(f\"Train Accuracy:{np.mean(train_accuracy)}, Test Accuracy:{np.mean(test_accuracy)}\\n\")\n",
        "\n"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:84: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, train loss: 3.0713974968882827, test loss: 3.0808904872221103\n",
            "\n",
            "Train Accuracy:0.05254569190600522, Test Accuracy:0.042279411764705885\n",
            "\n",
            "Epoch 2, train loss: 3.070624207080811, test loss: 3.0808904872221103\n",
            "\n",
            "Train Accuracy:0.05254569190600522, Test Accuracy:0.042279411764705885\n",
            "\n",
            "Epoch 3, train loss: 3.070624207080811, test loss: 3.0808904872221103\n",
            "\n",
            "Train Accuracy:0.05254569190600522, Test Accuracy:0.042279411764705885\n",
            "\n",
            "Epoch 4, train loss: 3.070624207080811, test loss: 3.0808904872221103\n",
            "\n",
            "Train Accuracy:0.05254569190600522, Test Accuracy:0.042279411764705885\n",
            "\n",
            "Epoch 5, train loss: 3.070624207080811, test loss: 3.0808904872221103\n",
            "\n",
            "Train Accuracy:0.05254569190600522, Test Accuracy:0.042279411764705885\n",
            "\n",
            "Epoch 6, train loss: 3.070297836323631, test loss: 3.079052251927993\n",
            "\n",
            "Train Accuracy:0.05287206266318538, Test Accuracy:0.04411764705882353\n",
            "\n",
            "Epoch 7, train loss: 3.070297836323631, test loss: 3.0808904872221103\n",
            "\n",
            "Train Accuracy:0.05287206266318538, Test Accuracy:0.042279411764705885\n",
            "\n",
            "Epoch 8, train loss: 3.070297836323631, test loss: 3.0808904872221103\n",
            "\n",
            "Train Accuracy:0.05287206266318538, Test Accuracy:0.042279411764705885\n",
            "\n",
            "Epoch 9, train loss: 3.070624207080811, test loss: 3.0808904872221103\n",
            "\n",
            "Train Accuracy:0.05254569190600522, Test Accuracy:0.042279411764705885\n",
            "\n",
            "Epoch 10, train loss: 3.070297836323631, test loss: 3.079052251927993\n",
            "\n",
            "Train Accuracy:0.05287206266318538, Test Accuracy:0.04411764705882353\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPTMIiOzQuFw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PWssc397nLn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}